\chapter{Application à la réalité augmentée}
\label{chapitre:RA}
\defineHeaderForClassicalChapter
\graphicspath{{images/Ch6/}}


\begin{chapeauChapitre}
Après avoir détaillé dans les chapitres précédent les différentes itérations de notre modèle JOLIMAS primal \ref{chapitre:primal_jolimas}, dual \ref{chapitre:dual_jolimas} et canonique \ref{chapitre:modele_general}, nous détaillons ici comment nous avons utilisé les résultats de prédiction de spécularité afin d'obtenir un rendu en réalité augmentée. Nous présentons plusieurs itération d'une application de retexturing qui consiste à substituer la texture d'une surface à une autre tout en conservant son contexte lumineux comme les variations d'intensité, les spécularités et les ombres).
De plus, nous détaillons la gestion de contexte complexes comme le multi-lumières, les lumières à état changeant pouvant s'éteindre et s'allumer.
\end{chapeauChapitre}

%===============================================================================
\section{Introduction}
\label{sec:introduction_general}
%===============================================================================
Dans \cite{blake1990does}, il a démontré que la perception humaine prend en compte les spécularités pour mieux comprendre une scène (géométrie, illumination). Pour ces raisons, la modélisation des sources de lumière et plus particulièrement la prédiction des spécularité peut potentiellement améliorer les applications suivantes:
\begin{itemize}
    \item Le retexturing en réalité augmenté
    \item La réalité diminuée et plus particulièrement lorsqu'une spécularité traverse une zone de l'image à restaurer \cite{kawaidiminished, herling2014high, said2017image}
    \item Synthétiser des points de vue inconnus à partir d'un flux vidéo (où la caméra n'est jamais allé physiquement)
\end{itemize}

\fix{Liste qui décrit le sommaire}

%=============================================================================
\section{Contexte multi-lumières} 
\label{sec:contexte_multi_lumieres}
%=============================================================================


\subsection{Suivi de spécularités}
Une composante additionnelle de notre modèle est sa capacité à prédire plusieurs spécularités provenant de différentes sources de lumière. En effet, sur des surfaces planes, une spécularité est associée à une seule source de lumière. En annotant et en suivant le déplacement de ces éléments, plusieurs quadriques peuvent être reconstruites à la fois. Après le processus de détection de spécularité, nous suivons le mouvement de chaque spécularité pour chaque image. Le suivi de spécularité est essentiel pour compter et distinguer les sources de lumières. Notre suivi est réalisé en calculant l'évolution des contours de spécularité d'une image à l'autre en détectant les intersections entre les contours de l'image courante et la précédente comme illustré dans la figure \ref{fig:synt_multi}. Même si le mouvement de caméra est conséquent, les spécularités suivent naturellement le mouvement de la caméra (plus particulièrement pour les surfaces planes), permettant à notre algorithme d'être robuste à des cas complexes. Ce suivi est réalisé pour chaque image en utilisant l'algorithme de détection de contour de \cite{suzuki1985topological} afin d'avoir des contours précis extraits de l'image binaire produite par notre méthode de détection de spécularité en temps réel. Cependant, suivre des spécularités se chevauchant (lorsque deux sources de lumière ont la même direction d'observation par rapport au point de vue) n'est pas encore géré par notre méthode, bien que ce cas reste relativement rare.

\begin{figure}[H]
\centering	    
   	  \subfigure[]
	  {
       		\includegraphics[width=0.473\linewidth]{real}
             \label{fig:multi_real}
      }   
      \subfigure[]
	  {
       		\includegraphics[width=0.473\linewidth]{conic}
             \label{fig:multi_real}
      }
      \subfigure[]
	  {
       		\includegraphics[width=0.473\linewidth]{real2}
             \label{fig:multi_real}
      }   
      \subfigure[]
	  {
       		\includegraphics[width=0.473\linewidth]{conic2}
             \label{fig:multi_real}
      }
      \caption{Annotation multi-lumière et suivi de spécularités (en bleu et rouge). (a) et (c) représentent deux points de vue différent d'une table en bois présentant deux spécularités. (b) et (d) représentent les ellipses associées à chaque source de lumière (en bleu et rouge).}
      \label{fig:synt_multi}
\end{figure}


\section{Filtrage multi-vues}
Pour des images surexposées, notre méthode de détection de spécularité peut confondre les textures blanches avec des spécularités. Afin d'assurer la robustesse de cette détection, un processus multi-vue sur les spécularités candidates s'impose. En détails, à l'opposé des contours 3D d'une texture, les contours 3D d'une spécularité se déplacent sur la surface lorsque la caméra se déplace. Ce phénomène est justifié du fait qu'une spécularité correspond à la réflexion d'une source de lumière qui elle est fixe. La specularité que nous observons correspond à un objet situé en dessous de la surface et non sur la surface, d'où le déplacement. En calculant l'homographie associé au plan où se présente la spécularité entre deux poses relativement éloignées, nous transformons (warping) les contours des spécularités candidates . Si le contours est suffisamment proche, le candidat est une texture. Dans le cas contraire, c'est une spécularité.


%=============================================================================
\section{Gestions de lumières à état changeant}
\label{sec:etat_changeant} 
%==============
Nous adressons ici l'analyse de l'état des spécularités en comparant la détection de spécularité dans une image et la prédiction produite par notre quadrique reconstruite. Cette analyse présente de nombreux intérêts:
\begin{itemize}
    \item Si les ellipses associées respectivement avec la prédiction et la détection ont la même forme mais une position différente, cela signifie probablement que la pose de caméra n'est pas assez précise.
    \item Si les ellipses associées respectivement avec la prédiction et la détection ont la même position mais une forme différente, cela signifie probablement que l'intensité de la lumière a changée ou que le matériau est différent.
    \item Si l'ellipse associée à la détection n'est plus présente, cela signifie que la source de lumière a été éteinte ou occultée.
\end{itemize} 
Ce dernier point sera abordé dans cette section. Il semble intuitif, qu'une source de lumière à état changeant (allumée ou éteinte) provoque des variations d'intensité conséquence dans l'image observée ce qui impacte fortement les algorithmes de vision par ordinateur. De plus, une caméra doit également s'adapter au nouveau contexte lumineux ce qui affectera le résultat des différentes applications de vision par ordinateur comme la segmentation, la reconstruction et la localisation. Actuellement, aucune solution n'explicite clairement ce problème. En utilisant la prédiction de spécularité de notre modèle JOLIMAS, nous pouvons suivre la spécularité créée par une source de lumière même si elle est éteinte ou allumée en comparant la prédiction et la détection de spécularité. Nous illustrons la capacité de notre modèle à prédire les spécularités des sources de lumières à état changeant (allumées et éteintes) dans la figure \ref{fig:changing_state}. Dans cette séquences, trois sources de lumières sont utilisées (deux lampes de bureau et une lampe néon) sur un comptoir de cuisine. Durant cette séquence, nous allumons et éteignions chaque source de lumière à tour de rôle avant d'éteindre toutes les sources de lumière en une seule fois à la fin de la séquence. Les résultats de cette séquence montre la capacité de notre modèle à gérer les changements d'état de lumière rapide tel que les clignotements de la lampe néon lors de l'allumage  dans un contexte multi-lumière.
\begin{figure}[H]
	\subfigure[]
	{
	    \includegraphics[width=0.48\linewidth]{multi_1.png}
	}
	\subfigure[]
	{
	    \includegraphics[width=0.48\linewidth]{multi_2.png}
	}
	\subfigure[]
	{
	    \includegraphics[width=0.48\linewidth]{multi_3.png}
	}
	\subfigure[]
	{
	    \includegraphics[width=0.48\linewidth]{multi_4.png}
	}
	\caption{Gestion des changements d'états de plusieurs sources de lumière. Les spécularités prédites sont représentées par des ellipses en bleu quand la lumière est allumée et en ellipses rouges dans le cas échéant. La première lampe de bureau est éteinte en (a) et le néon en (b). Dans (c) la première lampe de bureau et le néon sont allumés alors que la deuxième lampe de bureau est éteinte avant d'être rallumée. Dans (d), toutes les sources de lumière sont éteintes jusqu'à la fin de la séquence.}
	\label{fig:changing_state}
\end{figure}


%===============================================================================
\section{Changement de texture sur des objets réels}
\label{sec:retexturing}
%===============================================================================

Pour toutes ces applications, afin de synthétiser une spécularité dans une image, on peut envisager, dans un premier temps, de détecter/segmenter les spécularités dans une image et les appliquer directement sur une nouvelle texture. Cependant, détecter les spécularité de manière uniforme n'est pas une tâche triviale ce qui rend cette solution non optimale. En effet, les variations au niveau de la détection peuvent provoquer des incohérences temporelles et des vibrations non voulues comme illustré à la figure \ref{fig:temporal_incoherence}. De plus, la qualité de la détection de spécularité ne peut pas être garanti pour chaque point de vue à cause des changements de condition lumineuses, des limitations propres au détecteur (voir annexe \ref{annexe:specularity_detection}), des imperfections de la surface en terme de rugosité et d'occultations potentielles d'objets de la scène. Notons que la bonne gestion de la cohérence temporelle du rendu est particulièrement importante pour les applications comme la réalité diminuée \cite{kawaidiminished, herling2014high, said2017image}.

\subsection{Première approche : modélisation par fonction Gaussienne pour surface planes}

Afin de répondre au problème de cohérence temporelle pour la synthèse de spécularité lors du retexturing, nous utilisons notre modèle JOLIMAS. En effet, celui-ci est une solution naturelle car notre prédiction de spécularité est majoritairement dépendante de la stabilité de la pose de la caméra vu que cette prédiction est obtenue par projection de la quadrique à partir de la pose de caméra.
 \begin{figure}[!ht]
 \centering
     \subfigure[]
     {
         \includegraphics[width=0.4\linewidth]{error_conic.png}
     }
     \subfigure[]
     {
         \includegraphics[width=0.4\linewidth]{error_retext.png}
     }
     \subfigure[]
     {
         \includegraphics[width=0.9\linewidth]{jittering}
     }
     \caption{Illustration d'incohérences temporelles en utilisant un calcul d'ellipse pour une application de retexturing dans une séquence multi-lumière présenté dans la figure  \ref{fig:realdata_kitchen} pour trois images consécutives (une image par ligne de (a) et (b)). Dans (a), un tremblement sur le processus de calcul d'ellipse est visible pour chaque spécularité où nous calculons l'ellipse directement à partir de la détection de spécularité. Ce tremblement est illustré dans (c) en mesurant l'évolution des demi-axes ($S_x$ et $S_Y$) de l'ellipse calculée (approche basique) comparé à l'ellipse prédite par notre modèle (JOLIMAS) pour chaque image de la séquence du tableau présentée dans la figure \ref{fig:realdata_whiteboard}. Dans (b), nous copions directement le résultat de la détection de spécularité sur la nouvelle texture ce qui provoque un décalage en terme d'intensité qui est difficile à estomper avec la texture. De plus, cette méthode est sensible à la qualité de la détection de spécularité et ne peut pas prédire de nouveaux points de vues.}
     \label{fig:temporal_incoherence}    
 \end{figure}
Afin de synthétiser une spécularité à partir de JOLIMAS, il est nécessaire d'avoir une fonction d'intensité décrivant la variation d'intensité de la spécularité. Nous proposons une approximation basé sur une fonction gaussienne 2D. En effet, une spécularité peut être décrite comme une zone de forte intensité par rapport au reste de l'image. La function d'intensité gaussienne suit deux propriétés essentielles de la spécularité : une variation progressive de l'intensité et des isocontours de forme elliptique comme détaillé dans le chaptire \ref{chapitre:primal_jolimas}. La propriété de variation progressive a déjà été exploité dans la méthode de \cite{kim2013specular} afin de séparer les composantes spéculaires et diffuses dans une image. Notre méthode de retexturing est divisée en trois étapes. Premièrement, à partir des spécularités détections dans la séquence, une couleur moyenne de la spécularité est calculée afin de correspondre aux conditions d'illuminations. La fonction gaussienne appropriée est calculée sur les canaux rouge, vert et bleu afin de correspondre aux spécularités détectées dans les séquences. Afin de synthétiser les spécularités sur la texture associée à la surface, deux homographies sont calculées $\mathtt{H}_2$ qui correspond à la transformation des points de la texture jusqu'aux points de la surface et $\mathtt{H}_1$ qui transforme le cercle unitaire en notre conique prédite (la conique est d'abord transformée par $\mathtt{H}_2^{-1}$). Nous texture synthétique remplace la surface en fusionnant la texture avec notre texture gaussienne en utilisant $\mathtt{H}_1$ et nous transformons cette fusion sur la surface en utilisant $\mathtt{H}_2$. Quatre résultats de retexturing sont illustrées dans la figure \ref{fig:retexturing}.
\begin{figure*}[!ht]
	\subfigure[]
	{
		\includegraphics[width=\linewidth]{retext1.png}
		\label{fig:retexturing_howto}
	}
	\subfigure[]
	{
		\includegraphics[width=\linewidth]{retext4.png}
		\label{fig:retexturing_res4}
	}
	\subfigure[]
	{
		\includegraphics[width=\linewidth]{retext5.png}
		\label{fig:retexturing_res5}
	}
	\subfigure[]
	{
		\includegraphics[width=\linewidth]{retext2.png}
		\label{fig:retexturing_res}
	}
	\caption{Comparaisons des méthodes de retexturing de notre implémentation de \cite{buteau2015poster} (milieu) et notre approche (droite).  La méthode de \cite{buteau2015poster} étant une méthode pour reconstruction les sources de lumière ponctuelles, nous avons manuellement ajouter la rugosité, la couleur et l'intensité de la source de lumière en utilisant le modèle d'illumination locale de Phong. Nous utilisons uniquement le terme spéculaire. Le retexturing est illustré sur la séquence ampoule/table de fer (a) en utilisant une texture de marbre, (b) la séquence ampoule/libre en changeant la couverture du livre par une autre, (c) la séquence néon/ampoule/table en bois en changeant la texture de bois d'une table en une autre et (d) la séquence multi-lumière/comptoir de cuisine en utilisant une texture de roche. Sans prendre en compte le terme diffus sur la texture, la texture de la surface peut être changé de façon réaliste en utilisant uniquement le terme spéculaire prédis par JOLIMAS. Contrairement à l'approche de \cite{buteau2015poster}, nous calculons de façon précise la forme, la position et l'intensité de la spécularité avec un temps d'exécution faible et pour un résultat réaliste. De plus, calculer l'illumination à partir de modèles comme celui de Phong ne peut pas être fait sans apriori sur les matériaux et le nombre de sources lumineuses.}
	\label{fig:retexturing}
\end{figure*}
A cause du manque de méthodes pour la modélisation géométrique de spécularité comme JOLIMAS, nous avons implémenté l'approche de \cite{buteau2015poster} comme méthode de comparaison pour notre retexturing. Cette approche relativement récente reconstruit des sources de lumière ponctuelle à partir des spécularités pour des scène contenant des surfaces planes ce qui la rend assez proche de notre première itération de JOLIMAS (primal). Afin de réaliser l'application de retexturing pour des sources de lumières ponctuelles, nous calculons manuelles chaque paramètres du modèle d'illumination de Phong (rugosité, intensité et couleurs des sources de lumière) et appliquons ces paramètres seulement pour le terme spéculaire pour générer la nouvelle texture. Comme illustré à la figure \ref{fig:retexturing}, notre approche synthétise de façon précise l'intensité, la forme et la position des spécularités contrairement que \cite{buteau2015poster} qui créer des spécularités de meilleur qualité mais avec une mauvaise position et une mauvaise taille. De plus, pour les exemples présentés dans les figures \ref{fig:retexturing_howto} et \ref{fig:retexturing_res4}, les modèles d'illumination locale comme celui de Phong ne sont pas capable de prédire correctement la forme et la variation d'intensité de la spécularité. En utilisant uniquement des sources de lumière ponctuelles, il est difficile de modéliser les sources de lumière étendue. La simplicité de notre méthode nous permet de fournir de bon résultats pour les surfaces planes.
Dans la section suivante, nous montrons comment nous avons généralisé ce processus pour tout types de surfaces et amélioré le rendu en calculant le terme diffus afin de rajouter des effets d'ombres.


\subsection{Deuxième approche : Retexturing pour tout types de surfaces}
\begin{figure*}[!ht]
   \centering	
        \includegraphics[width=\linewidth]{retext_pipeline.pdf}
	  \caption{Pipeline du processus de retexturing généralisé. La méthode est divisée en trois phases : la reconstruction de spécularité à partir des images utilisées pour la reconstruction de la quadrique 3D (partie du haut), calcul du terme diffus (partie du bas) et fusion de la spécularité synthétisée, la spécularité prédite et le terme diffus. La spécularité est reconstruite en termes de variation d'intensité et de couleur de façon empirique à partir des coniques prédites et des spécularités détectées dans les images. Afin de calculer le terme diffus, nous considérons le centre des quadriques reconstruites comme étant des sources ponctuelles. Nous calculons ensuite le terme diffus de \cite{phong1975illumination}. La spécularité et le terme diffus sont ensuite fusionnés afin de créer la nouvelles texture associée à la surface. L'ajout du terme diffus combiné aux spécularités améliore drastiquement le rendu.}
	  \label{fig:retexturing}
\end{figure*}

Nous améliorons notre première approche de synthèse de spécularité en ajoutant un terme diffus qui est essentiel pour représenter les ombres et les variations d'intensité qui apparaissent sur des surfaces non-planes. Afin d'améliorer davantage le réalisme, nous calculons aussi l'intensité et la couleur de la spécularité empiriquement à partir de chasue image utilisé lors du processus de reconstruction de quadrique.
\paragraph{Calcul du terme diffus}
Nous considérons la texture d'entrée comme la composante ambiante utilisée dans le modèle de Phong. Afin d'ajouter le terme diffus, nous utilisons les centres des quadriques reconstruites comme étant la position des sources de lumière $\mbf{L}$ et nous calculons la composante diffuse pour chaque point de la surface $\mbf{P}$ avec:
\begin{equation}
I_d = \sum_{i=1}^{k} \left( \hat{\mbf{L}}_i(\mbf{P}) \cdot \hat{\mbf{N}}(\mbf{P}) \right),
\end{equation}
avec $I_d$ l'image diffuse, $k$ le nombre de sources de lumière et $i$ l'indenx de la source de lumière utilisée.

\paragraph{Reconstruction de la spécularité et fusion.}
Pour chaque image utilisées pour la reconstruction de la quadrique, nous utilisons les spécularités prédites et les spécularités détectées dans les images afin de reconstruire un motif de spécularité.
En mettant en correspondance les formes des différentes spécularités, nous calculons l'evolution de l'intensité et de la couleur de la spécularité. Afin d'assurer une fusion entre la spécularité et la nouvelle texture, nous interpolons la couleur aux bordures de la spécularité avec le terme diffus atour de celle-ci. Nous détaillons le pipeline complète à la figure \ref{fig:retexturing}.

\begin{figure}[!ht]
   \centering	  
        \includegraphics[width=\linewidth]{retexturing_example.png}
	  \caption{Exemples de retexturing sur trois séquences : la table de billard, le mug et le vase jaune. Nous pouvons voir que les spécularités synthétisées ainsi que les ombres sont cohérentes avec le contexte lumineux des images d'entrées.}
	  \label{fig:retexturing_example}
\end{figure}
Comme illustré dans la figure \ref{fig:retexturing_example}, notre application de retexturing permet de synthétiser l'intensité et la couleur de la spécularité et de créer un rendu cohérent en temps réel.

%Maybe an advanced intensity function here ?
%In this document, we mainly focused on a dynamic retexturing application using a new intensity function to fill the inside of the predicted conic. \fix{BP + TODO}.

%Specularity prediction allows several applications in computer vision:
%\begin{itemize}
%    \item Detecting the state of a light source (on/off). By comparing the detected specularity and the predicted specularity, if the predicted conic does not match the detected specularity, the light is turned off and reciprocally.
%    
%   \item Improve the camera pose estimation by using the prediction as a geometric primitive. Using the 2D distance of \cite{sturm2007conic}, we can compare the predicted and detected specularity and further constrain the camera pose.
%\end{itemize}

%===============================================================================
%\section{Changements synthétiques de rugosité et de source lumineuses}
%\label{sec:changements_ra}
%===============================================================================


%===============================================================================
\section{Limitations}
\label{sec:limitations_ra}
%===============================================================================


\paragraph{Croisements de spécularités}
Si la caméra observe une scène dans une direction tel que deux sources de lumières ont un alignement similaire, les deux spécularités résultantes peuvent se croiser dans l'image. Ce phénomène met en échec le suivi et donc la labelisation de spécularités. Actuellement, ce problème n'est pas géré dans notre application mais pourrait être adressé si les sources de lumière sont de couleurs différentes. Cependant, pour des sources de lumière similaires (forme et couleur), la seule façon de distinguer clairement les spécularités est d'utiliser une information 3D (reconstruire une source de lumière ponctuelle à partir de deux points de vue par triangulation par exemple) afin de s'assure de la cohérence du mouvement des la spécularité. Dans tous les cas, les images où les spécularités se croisent doivent être exclues de notre reconstruction.

%\fix{More ? Parler du formalisme pour le multi plan qui sera résolu par JOLIMAS dual}

%===============================================================================
%\section{Résultats}
\section{Temps d'exécution}
\label{sec:resultats_ra}
%===============================================================================

\subsection{Temps d'exécution}
Dans la table \ref{tab:computation_time}, nous présentons le temps d'exécution de chaque étape de notre méthode incluant la détection de spécularité, le calcul de point d'intensité maximale, la reconstruction de quadrique et le retexturing. Nous calculons les résultats sur un processeur Intel i7  de fréquence 2.70 GHz sur des séquences réelles présentées dans la figure \ref{fig:sequences}. La reconstruction de quadrique prend 76.2 millisecondes en moyenne et est réalisée quand un minimum de 6 images clés est atteint. La quadrique est raffinée pour chaque nouvelle image clé mais prend cette fois ci 15 millisecondes en moyenne car seulement quelques itérations sont nécessaires contrairement au raffinement initial. Notre analyse a été réalisée sans utilisation de GPU ou de parallélisation.

\begin{table}[!ht]
\caption{Calcul du temps d'exécution de la prédiction de spécularité de JOLIMAS dual. Notre méthode tourne en temps réel.}
 \centering
  \begin{tabular}{c|c|} 
      \hline
        \multicolumn{1}{|c|}{ Étape de reconstruction de JOLIMAS dual} & Temps d'exécution (ms) \\      \hline
      \multicolumn{1}{|c|}{\specialcell{Détection de specularité }} & 12.1\\      \hline
       \multicolumn{1}{|c|}{\specialcell{Correction du point d'intensité maximale}} & 8.3 \\      \hline
       \multicolumn{1}{|c|}{\specialcell{Reconstruction de quadrique}}    & 76.2  \\      \hline
       \multicolumn{1}{|c|}{\specialcell{Prédiction de spécularité}}    & 2.4 \\      \hline
  \end{tabular}
  \label{tab:computation_time}
\end{table}

%===============================================================================
\section{Perspectives}
\label{sec:perspectives_ra}
%===============================================================================
A partir de notre modèle JOLIMAS, il est possible d'utiliser la quadrique comme bonne initialisation pour n'importe quel modèle d'illumination locale comme \cite{torrance1967theory, cook1982reflectance} de façon similaire à ce qui a été fait dans la section \ref{sec:retexturing}. Combiné à une étape de raffinement non-linéaire pour calculer/raffiner les autres paramètres comme la couleur, l'intensité voire la position de la source de lumière. Une autre extension serait également d'utiliser les spécularités pour calculer une carte de normale afin de mesurer la rugosité. En effet, comme observé à la figure \ref{fig:roughness}, les spécularités mettent en valeur la rugosité sur des surfaces qui semblent majoritairement planes. 

\begin{figure}[!ht]
\subfigure[]
	{
		\includegraphics[width=0.47\linewidth]{roughness.PNG}
	}
	\subfigure[]
	{
		\includegraphics[width=0.47\linewidth]{roughness2.PNG}
	}
	\caption{Illustration de la rugosité mise en évidence par la spécularité. Une surface paraissant comme plane et lisse se révèle comme rugueuse.}
	\label{fig:roughness}
\end{figure}

%===============================================================================
\section{Conclusion}
\label{sec:conclusion_ra}
%===============================================================================

\fix{La capacité de prédiction de spécularité de notre modèle nous permet également de détecter les lumières à état changeant (allumées et éteintes) dans un contexte multi-lumières. Nous montrerons dans le chapitre \ref{chapitre:RA} que le modèle JOLIMAS pouvait être utilisé pour améliorer le rendu des application de réalité augmentée. En complément, notre prédiction de spécularité pourrait améliorer grandement les algorithmes de localisation de caméra. Pour des applications d'infographie, le calcul du terme spéculaire de façon plus localisée pourrait optimiser le rendu par l'intermédiaire de notre procédé de prédiction.}
